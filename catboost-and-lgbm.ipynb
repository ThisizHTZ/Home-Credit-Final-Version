{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6db5283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:54:11.710296Z",
     "iopub.status.busy": "2025-10-19T04:54:11.709995Z",
     "iopub.status.idle": "2025-10-19T04:54:24.458192Z",
     "shell.execute_reply": "2025-10-19T04:54:24.457515Z"
    },
    "papermill": {
     "duration": 12.753765,
     "end_time": "2025-10-19T04:54:24.459659",
     "exception": false,
     "start_time": "2025-10-19T04:54:11.705894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 19 04:54:16 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   34C    P0             25W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm --quiet\n",
    "!nvidia-smi\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import polars as pl \n",
    "import warnings\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool \n",
    "from glob import glob\n",
    "from IPython.display import display  \n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin \n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.model_selection import StratifiedGroupKFold  \n",
    "from typing import Any\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT = Path(\"../input/home-credit-credit-risk-model-stability\")\n",
    "TRAIN_DIR = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR = ROOT / \"parquet_files\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebbd764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:54:24.467006Z",
     "iopub.status.busy": "2025-10-19T04:54:24.466562Z",
     "iopub.status.idle": "2025-10-19T04:54:24.485615Z",
     "shell.execute_reply": "2025-10-19T04:54:24.484889Z"
    },
    "papermill": {
     "duration": 0.023928,
     "end_time": "2025-10-19T04:54:24.486781",
     "exception": false,
     "start_time": "2025-10-19T04:54:24.462853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Utility:\n",
    "    @staticmethod\n",
    "    def get_feat_defs(ending_with: str) -> None:\n",
    "        \"\"\"\n",
    "        Retrieves feature definitions from a CSV file based on the specified ending.\n",
    "\n",
    "        Args:\n",
    "        - ending_with (str): Ending to filter feature definitions.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: Filtered feature definitions.\n",
    "        \"\"\"\n",
    "        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n",
    "\n",
    "        filtered_feats: pl.DataFrame = feat_defs.filter(\n",
    "            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n",
    "        )\n",
    "\n",
    "        with pl.Config(fmt_str_lengths=200, tbl_rows=-1):\n",
    "            print(filtered_feats)\n",
    "\n",
    "        filtered_feats = None\n",
    "        feat_defs = None\n",
    "\n",
    "    @staticmethod\n",
    "    def find_index(lst: list[Any], item: Any) -> int | None:\n",
    "        \"\"\"\n",
    "        Finds the index of an item in a list.\n",
    "\n",
    "        Args:\n",
    "        - lst (list): List to search.\n",
    "        - item (Any): Item to find in the list.\n",
    "\n",
    "        Returns:\n",
    "        - int | None: Index of the item if found, otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return lst.index(item)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def dtype_to_str(dtype: pl.DataType) -> str:\n",
    "        \"\"\"\n",
    "        Converts Polars data type to string representation.\n",
    "\n",
    "        Args:\n",
    "        - dtype (pl.DataType): Polars data type.\n",
    "\n",
    "        Returns:\n",
    "        - str: String representation of the data type.\n",
    "        \"\"\"\n",
    "        dtype_map = {\n",
    "            pl.Decimal: \"Decimal\",\n",
    "            pl.Float32: \"Float32\",\n",
    "            pl.Float64: \"Float64\",\n",
    "            pl.UInt8: \"UInt8\",\n",
    "            pl.UInt16: \"UInt16\",\n",
    "            pl.UInt32: \"UInt32\",\n",
    "            pl.UInt64: \"UInt64\",\n",
    "            pl.Int8: \"Int8\",\n",
    "            pl.Int16: \"Int16\",\n",
    "            pl.Int32: \"Int32\",\n",
    "            pl.Int64: \"Int64\",\n",
    "            pl.Date: \"Date\",\n",
    "            pl.Datetime: \"Datetime\",\n",
    "            pl.Duration: \"Duration\",\n",
    "            pl.Time: \"Time\",\n",
    "            pl.Array: \"Array\",\n",
    "            pl.List: \"List\",\n",
    "            pl.Struct: \"Struct\",\n",
    "            pl.String: \"String\",\n",
    "            pl.Categorical: \"Categorical\",\n",
    "            pl.Enum: \"Enum\",\n",
    "            pl.Utf8: \"Utf8\",\n",
    "            pl.Binary: \"Binary\",\n",
    "            pl.Boolean: \"Boolean\",\n",
    "            pl.Null: \"Null\",\n",
    "            pl.Object: \"Object\",\n",
    "            pl.Unknown: \"Unknown\",\n",
    "        }\n",
    "\n",
    "        return dtype_map.get(dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_feat_occur(regex_path: str, ending_with: str) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Finds occurrences of features ending with a specific string in Parquet files.\n",
    "\n",
    "        Args:\n",
    "        - regex_path (str): Regular expression to match Parquet file paths.\n",
    "        - ending_with (str): Ending to filter feature names.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: DataFrame containing feature definitions, data types, and file locations.\n",
    "        \"\"\"\n",
    "        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\").filter(\n",
    "            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n",
    "        )\n",
    "        feat_defs.sort(by=[\"Variable\"])\n",
    "\n",
    "        feats: list[pl.String] = feat_defs[\"Variable\"].to_list()\n",
    "        feats.sort()\n",
    "\n",
    "        occurrences: list[list] = [[set(), set()] for _ in range(feat_defs.height)]\n",
    "\n",
    "        for path in glob(str(regex_path)):\n",
    "            df_schema: dict = pl.read_parquet_schema(path)\n",
    "\n",
    "            for feat, dtype in df_schema.items():\n",
    "                index: int = Utility.find_index(feats, feat)\n",
    "                if index != None:\n",
    "                    occurrences[index][0].add(Utility.dtype_to_str(dtype))\n",
    "                    occurrences[index][1].add(Path(path).stem)\n",
    "\n",
    "        data_types: list[str] = [None] * feat_defs.height\n",
    "        file_locs: list[str] = [None] * feat_defs.height\n",
    "\n",
    "        for i, feat in enumerate(feats):\n",
    "            data_types[i] = list(occurrences[i][0])\n",
    "            file_locs[i] = list(occurrences[i][1])\n",
    "\n",
    "        feat_defs = feat_defs.with_columns(pl.Series(data_types).alias(\"Data_Type(s)\"))\n",
    "        feat_defs = feat_defs.with_columns(pl.Series(file_locs).alias(\"File_Loc(s)\"))\n",
    "\n",
    "        return feat_defs\n",
    "\n",
    "    def reduce_memory_usage(df: pl.DataFrame, name) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Reduces memory usage of a DataFrame by converting column types.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.DataFrame): DataFrame to optimize.\n",
    "        - name (str): Name of the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: Optimized DataFrame.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f\"Memory usage of dataframe \\\"{name}\\\" is {round(df.estimated_size('mb'), 4)} MB.\"\n",
    "        )\n",
    "\n",
    "        int_types = [\n",
    "            pl.Int8,\n",
    "            pl.Int16,\n",
    "            pl.Int32,\n",
    "            pl.Int64,\n",
    "            pl.UInt8,\n",
    "            pl.UInt16,\n",
    "            pl.UInt32,\n",
    "            pl.UInt64,\n",
    "        ]\n",
    "        float_types = [pl.Float32, pl.Float64]\n",
    "\n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtype\n",
    "            if col_type in int_types + float_types:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if c_min is not None and c_max is not None:\n",
    "                    if col_type in int_types:\n",
    "                        if c_min >= 0:\n",
    "                            if (\n",
    "                                c_min >= np.iinfo(np.uint8).min\n",
    "                                and c_max <= np.iinfo(np.uint8).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt8))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint16).min\n",
    "                                and c_max <= np.iinfo(np.uint16).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt16))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint32).min\n",
    "                                and c_max <= np.iinfo(np.uint32).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt32))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.uint64).min\n",
    "                                and c_max <= np.iinfo(np.uint64).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.UInt64))\n",
    "                        else:\n",
    "                            if (\n",
    "                                c_min >= np.iinfo(np.int8).min\n",
    "                                and c_max <= np.iinfo(np.int8).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int8))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int16).min\n",
    "                                and c_max <= np.iinfo(np.int16).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int16))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int32).min\n",
    "                                and c_max <= np.iinfo(np.int32).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int32))\n",
    "                            elif (\n",
    "                                c_min >= np.iinfo(np.int64).min\n",
    "                                and c_max <= np.iinfo(np.int64).max\n",
    "                            ):\n",
    "                                df = df.with_columns(df[col].cast(pl.Int64))\n",
    "                    elif col_type in float_types:\n",
    "                        if (\n",
    "                            c_min > np.finfo(np.float32).min\n",
    "                            and c_max < np.finfo(np.float32).max\n",
    "                        ):\n",
    "                            df = df.with_columns(df[col].cast(pl.Float32))\n",
    "\n",
    "        print(\n",
    "            f\"Memory usage of dataframe \\\"{name}\\\" became {round(df.estimated_size('mb'), 4)} MB.\"\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def to_pandas(df: pl.DataFrame, cat_cols: list[str] = None) -> (pd.DataFrame, list[str]):  # type: ignore\n",
    "        \"\"\"\n",
    "        Converts a Polars DataFrame to a Pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.DataFrame): Polars DataFrame to convert.\n",
    "        - cat_cols (list[str]): List of categorical columns. Default is None.\n",
    "\n",
    "        Returns:\n",
    "        - (pd.DataFrame, list[str]): Tuple containing the converted Pandas DataFrame and categorical columns.\n",
    "        \"\"\"\n",
    "        df: pd.DataFrame = df.to_pandas()\n",
    "\n",
    "        if cat_cols is None:\n",
    "            cat_cols = list(df.select_dtypes(\"object\").columns)\n",
    "\n",
    "        df[cat_cols] = df[cat_cols].astype(\"str\")\n",
    "\n",
    "        return df, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e347061c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:54:24.493018Z",
     "iopub.status.busy": "2025-10-19T04:54:24.492816Z",
     "iopub.status.idle": "2025-10-19T04:54:24.501692Z",
     "shell.execute_reply": "2025-10-19T04:54:24.500986Z"
    },
    "papermill": {
     "duration": 0.013403,
     "end_time": "2025-10-19T04:54:24.502877",
     "exception": false,
     "start_time": "2025-10-19T04:54:24.489474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    @staticmethod\n",
    "    def max_expr(df: pl.LazyFrame) -> list[pl.Series]:\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating maximum values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for maximum values.\n",
    "        \"\"\"\n",
    "        cols: list[str] = [\n",
    "            col\n",
    "            for col in df.columns\n",
    "            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n",
    "        ]\n",
    "\n",
    "        expr_max: list[pl.Series] = [\n",
    "            pl.col(col).max().alias(f\"max_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def min_expr(df: pl.LazyFrame) -> list[pl.Series]:\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating minimum values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for minimum values.\n",
    "        \"\"\"\n",
    "        cols: list[str] = [\n",
    "            col\n",
    "            for col in df.columns\n",
    "            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n",
    "        ]\n",
    "\n",
    "        expr_min: list[pl.Series] = [\n",
    "            pl.col(col).min().alias(f\"min_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_min\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_expr(df: pl.LazyFrame) -> list[pl.Series]:\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating mean values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for mean values.\n",
    "        \"\"\"\n",
    "        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n",
    "\n",
    "        expr_mean: list[pl.Series] = [\n",
    "            pl.col(col).mean().alias(f\"mean_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_mean\n",
    "\n",
    "    @staticmethod\n",
    "    def var_expr(df: pl.LazyFrame) -> list[pl.Series]:\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating variance for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for variance.\n",
    "        \"\"\"\n",
    "        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n",
    "\n",
    "        expr_mean: list[pl.Series] = [\n",
    "            pl.col(col).var().alias(f\"var_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_mean\n",
    "\n",
    "    @staticmethod\n",
    "    def mode_expr(df: pl.LazyFrame) -> list[pl.Series]:\n",
    "        \"\"\"\n",
    "        Generates expressions for calculating mode values for specific columns.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of expressions for mode values.\n",
    "        \"\"\"\n",
    "        cols: list[str] = [col for col in df.columns if col.endswith(\"M\")]\n",
    "\n",
    "        expr_mode: list[pl.Series] = [\n",
    "            pl.col(col).drop_nulls().mode().first().alias(f\"mode_{col}\") for col in cols\n",
    "        ]\n",
    "\n",
    "        return expr_mode\n",
    "\n",
    "    @staticmethod\n",
    "    def get_exprs(df: pl.LazyFrame) -> list[pl.Series]:\n",
    "        \"\"\"\n",
    "        Combines expressions for maximum, mean, and variance calculations.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - list[pl.Series]: List of combined expressions.\n",
    "        \"\"\"\n",
    "        exprs = (\n",
    "            Aggregator.max_expr(df) + Aggregator.mean_expr(df) + Aggregator.var_expr(df)\n",
    "        )\n",
    "\n",
    "        return exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b1d111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:54:24.509006Z",
     "iopub.status.busy": "2025-10-19T04:54:24.508808Z",
     "iopub.status.idle": "2025-10-19T04:54:24.517258Z",
     "shell.execute_reply": "2025-10-19T04:54:24.516564Z"
    },
    "papermill": {
     "duration": 0.012775,
     "end_time": "2025-10-19T04:54:24.518300",
     "exception": false,
     "start_time": "2025-10-19T04:54:24.505525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SchemaGen:\n",
    "    @staticmethod\n",
    "    def change_dtypes(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "        \"\"\"\n",
    "        Changes the data types of columns in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "        - df (pl.LazyFrame): Input LazyFrame.\n",
    "\n",
    "        Returns:\n",
    "        - pl.LazyFrame: LazyFrame with modified data types.\n",
    "        \"\"\"\n",
    "        for col in df.columns:\n",
    "            if col == \"case_id\":\n",
    "                df = df.with_columns(pl.col(col).cast(pl.UInt32).alias(col))\n",
    "            elif col in [\"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.UInt16).alias(col))\n",
    "            elif col == \"date_decision\" or col[-1] == \"D\":\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date).alias(col))\n",
    "            elif col[-1] in [\"P\", \"A\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def scan_files(glob_path: str, depth: int = None) -> pl.LazyFrame:\n",
    "        \"\"\"\n",
    "        Scans Parquet files matching the glob pattern and combines them into a LazyFrame.\n",
    "\n",
    "        Args:\n",
    "        - glob_path (str): Glob pattern to match Parquet files.\n",
    "        - depth (int, optional): Depth level for data aggregation. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "        - pl.LazyFrame: Combined LazyFrame.\n",
    "        \"\"\"\n",
    "        chunks: list[pl.LazyFrame] = []\n",
    "        for path in glob(str(glob_path)):\n",
    "            df: pl.LazyFrame = pl.scan_parquet(\n",
    "                path, low_memory=True, rechunk=True\n",
    "            ).pipe(SchemaGen.change_dtypes)\n",
    "            print(f\"File {Path(path).stem} loaded into memory.\")\n",
    "\n",
    "            if depth in (1, 2):\n",
    "                exprs: list[pl.Series] = Aggregator.get_exprs(df)\n",
    "                df = df.group_by(\"case_id\").agg(exprs)\n",
    "\n",
    "                del exprs\n",
    "                gc.collect()\n",
    "\n",
    "            chunks.append(df)\n",
    "\n",
    "        df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "\n",
    "        del chunks\n",
    "        gc.collect()\n",
    "\n",
    "        df = df.unique(subset=[\"case_id\"])\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def join_dataframes(\n",
    "        df_base: pl.LazyFrame,\n",
    "        depth_0: list[pl.LazyFrame],\n",
    "        depth_1: list[pl.LazyFrame],\n",
    "        depth_2: list[pl.LazyFrame],\n",
    "    ) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Joins multiple LazyFrames with a base LazyFrame.\n",
    "\n",
    "        Args:\n",
    "        - df_base (pl.LazyFrame): Base LazyFrame.\n",
    "        - depth_0 (list[pl.LazyFrame]): List of LazyFrames for depth 0.\n",
    "        - depth_1 (list[pl.LazyFrame]): List of LazyFrames for depth 1.\n",
    "        - depth_2 (list[pl.LazyFrame]): List of LazyFrames for depth 2.\n",
    "\n",
    "        Returns:\n",
    "        - pl.DataFrame: Joined DataFrame.\n",
    "        \"\"\"\n",
    "        for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "            df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "\n",
    "        return df_base.collect().pipe(Utility.reduce_memory_usage, \"df_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd24a149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:54:24.524678Z",
     "iopub.status.busy": "2025-10-19T04:54:24.524310Z",
     "iopub.status.idle": "2025-10-19T04:54:24.531598Z",
     "shell.execute_reply": "2025-10-19T04:54:24.531071Z"
    },
    "papermill": {
     "duration": 0.011758,
     "end_time": "2025-10-19T04:54:24.532642",
     "exception": false,
     "start_time": "2025-10-19T04:54:24.520884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_cols(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters columns in the DataFrame based on null percentage and unique values for string columns.\n",
    "\n",
    "    Args:\n",
    "    - df (pl.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pl.DataFrame: DataFrame with filtered columns.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]:\n",
    "            null_pct = df[col].is_null().mean()\n",
    "\n",
    "            if null_pct > 0.95:\n",
    "                df = df.drop(col)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if (col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]) & (\n",
    "            df[col].dtype == pl.String\n",
    "        ):\n",
    "            freq = df[col].n_unique()\n",
    "\n",
    "            if (freq > 200) | (freq == 1):\n",
    "                df = df.drop(col)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform_cols(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforms columns in the DataFrame according to predefined rules.\n",
    "\n",
    "    Args:\n",
    "    - df (pl.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pl.DataFrame: DataFrame with transformed columns.\n",
    "    \"\"\"\n",
    "    if \"riskassesment_302T\" in df.columns:\n",
    "        if df[\"riskassesment_302T\"].dtype == pl.Null:\n",
    "            df = df.with_columns(\n",
    "                [\n",
    "                    pl.Series(\n",
    "                        \"riskassesment_302T_rng\", df[\"riskassesment_302T\"], pl.UInt8\n",
    "                    ),\n",
    "                    pl.Series(\n",
    "                        \"riskassesment_302T_mean\", df[\"riskassesment_302T\"], pl.UInt8\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            pct_low: pl.Series = (\n",
    "                df[\"riskassesment_302T\"]\n",
    "                .str.split(\" - \")\n",
    "                .apply(lambda x: x[0].replace(\"%\", \"\"))\n",
    "                .cast(pl.UInt8)\n",
    "            )\n",
    "            pct_high: pl.Series = (\n",
    "                df[\"riskassesment_302T\"]\n",
    "                .str.split(\" - \")\n",
    "                .apply(lambda x: x[1].replace(\"%\", \"\"))\n",
    "                .cast(pl.UInt8)\n",
    "            )\n",
    "\n",
    "            diff: pl.Series = pct_high - pct_low\n",
    "            avg: pl.Series = ((pct_low + pct_high) / 2).cast(pl.Float32)\n",
    "\n",
    "            del pct_high, pct_low\n",
    "            gc.collect()\n",
    "\n",
    "            df = df.with_columns(\n",
    "                [\n",
    "                    diff.alias(\"riskassesment_302T_rng\"),\n",
    "                    avg.alias(\"riskassesment_302T_mean\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        df.drop(\"riskassesment_302T\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb3cf76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:54:24.538758Z",
     "iopub.status.busy": "2025-10-19T04:54:24.538557Z",
     "iopub.status.idle": "2025-10-19T04:54:24.542981Z",
     "shell.execute_reply": "2025-10-19T04:54:24.542453Z"
    },
    "papermill": {
     "duration": 0.008568,
     "end_time": "2025-10-19T04:54:24.543922",
     "exception": false,
     "start_time": "2025-10-19T04:54:24.535354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def handle_dates(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Handles date columns in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (pl.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pl.DataFrame: DataFrame with transformed date columns.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col.endswith(\"D\"):\n",
    "            df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n",
    "            df = df.with_columns(pl.col(col).dt.total_days().cast(pl.Int32))\n",
    "\n",
    "    df = df.rename(\n",
    "        {\n",
    "            \"MONTH\": \"month\",\n",
    "            \"WEEK_NUM\": \"week_num\"\n",
    "        }\n",
    "    )\n",
    "            \n",
    "    df = df.with_columns(\n",
    "        [\n",
    "            pl.col(\"date_decision\").dt.year().alias(\"year\").cast(pl.Int16),\n",
    "            pl.col(\"date_decision\").dt.day().alias(\"day\").cast(pl.UInt8),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return df.drop(\"date_decision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c681d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:54:24.550232Z",
     "iopub.status.busy": "2025-10-19T04:54:24.550007Z",
     "iopub.status.idle": "2025-10-19T04:54:28.718808Z",
     "shell.execute_reply": "2025-10-19T04:54:28.718077Z"
    },
    "papermill": {
     "duration": 4.173236,
     "end_time": "2025-10-19T04:54:28.719907",
     "exception": false,
     "start_time": "2025-10-19T04:54:24.546671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File train_base loaded into memory.\n",
      "File train_static_cb_0 loaded into memory.\n",
      "File train_static_0_0 loaded into memory.\n",
      "File train_static_0_1 loaded into memory.\n",
      "File train_applprev_1_1 loaded into memory.\n",
      "File train_applprev_1_0 loaded into memory.\n",
      "File train_tax_registry_a_1 loaded into memory.\n",
      "File train_tax_registry_b_1 loaded into memory.\n",
      "File train_tax_registry_c_1 loaded into memory.\n",
      "File train_credit_bureau_a_1_3 loaded into memory.\n",
      "File train_credit_bureau_a_1_2 loaded into memory.\n",
      "File train_credit_bureau_a_1_0 loaded into memory.\n",
      "File train_credit_bureau_a_1_1 loaded into memory.\n",
      "File train_credit_bureau_b_1 loaded into memory.\n",
      "File train_other_1 loaded into memory.\n",
      "File train_person_1 loaded into memory.\n",
      "File train_deposit_1 loaded into memory.\n",
      "File train_debitcard_1 loaded into memory.\n",
      "File train_credit_bureau_a_2_6 loaded into memory.\n",
      "File train_credit_bureau_a_2_1 loaded into memory.\n",
      "File train_credit_bureau_a_2_0 loaded into memory.\n",
      "File train_credit_bureau_a_2_7 loaded into memory.\n",
      "File train_credit_bureau_a_2_5 loaded into memory.\n",
      "File train_credit_bureau_a_2_2 loaded into memory.\n",
      "File train_credit_bureau_a_2_4 loaded into memory.\n",
      "File train_credit_bureau_a_2_9 loaded into memory.\n",
      "File train_credit_bureau_a_2_3 loaded into memory.\n",
      "File train_credit_bureau_a_2_10 loaded into memory.\n",
      "File train_credit_bureau_a_2_8 loaded into memory.\n",
      "File train_credit_bureau_b_2 loaded into memory.\n"
     ]
    }
   ],
   "source": [
    "data_store: dict = {\n",
    "    \"df_base\": SchemaGen.scan_files(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "    ],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b617043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:54:28.728056Z",
     "iopub.status.busy": "2025-10-19T04:54:28.727833Z",
     "iopub.status.idle": "2025-10-19T04:56:23.858389Z",
     "shell.execute_reply": "2025-10-19T04:56:23.857435Z"
    },
    "papermill": {
     "duration": 115.135743,
     "end_time": "2025-10-19T04:56:23.859610",
     "exception": false,
     "start_time": "2025-10-19T04:54:28.723867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe \"df_train\" is 7002.6003 MB.\n",
      "Memory usage of dataframe \"df_train\" became 4393.5639 MB.\n",
      "Memory usage of dataframe \"df_train\" is 2893.2785 MB.\n",
      "Memory usage of dataframe \"df_train\" became 2687.9916 MB.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train: pl.LazyFrame = (\n",
    "    SchemaGen.join_dataframes(**data_store)\n",
    "    .pipe(filter_cols)\n",
    "    .pipe(transform_cols)\n",
    "    .pipe(handle_dates)\n",
    "    .pipe(Utility.reduce_memory_usage, \"df_train\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b4deb4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:56:23.867819Z",
     "iopub.status.busy": "2025-10-19T04:56:23.867584Z",
     "iopub.status.idle": "2025-10-19T04:56:23.999157Z",
     "shell.execute_reply": "2025-10-19T04:56:23.998461Z"
    },
    "papermill": {
     "duration": 0.136766,
     "end_time": "2025-10-19T04:56:24.000220",
     "exception": false,
     "start_time": "2025-10-19T04:56:23.863454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1526659, 472)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 472)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>month</th><th>week_num</th><th>target</th><th>assignmentdate_238D</th><th>assignmentdate_4527235D</th><th>birthdate_574D</th><th>contractssum_5085716L</th><th>dateofbirth_337D</th><th>days120_123L</th><th>days180_256L</th><th>days30_165L</th><th>days360_512L</th><th>days90_310L</th><th>description_5085714M</th><th>education_1103M</th><th>education_88M</th><th>firstquarter_103L</th><th>fourthquarter_440L</th><th>maritalst_385M</th><th>maritalst_893M</th><th>numberofqueries_373L</th><th>pmtaverage_3A</th><th>pmtaverage_4527227A</th><th>pmtcount_4527229L</th><th>pmtcount_693L</th><th>pmtscount_423L</th><th>pmtssum_45A</th><th>requesttype_4525192L</th><th>responsedate_1012D</th><th>responsedate_4527233D</th><th>responsedate_4917613D</th><th>secondquarter_766L</th><th>thirdquarter_1082L</th><th>actualdpdtolerance_344P</th><th>amtinstpaidbefduel24m_4187115A</th><th>annuity_780A</th><th>&hellip;</th><th>mean_mainoccupationinc_384A</th><th>max_amount_416A</th><th>max_num_group1_10</th><th>max_openingdate_313D</th><th>mean_amount_416A</th><th>mean_openingdate_313D</th><th>max_num_group1_11</th><th>max_openingdate_857D</th><th>mean_openingdate_857D</th><th>max_collater_typofvalofguarant_298M</th><th>max_collater_typofvalofguarant_407M</th><th>max_collater_valueofguarantee_1124L</th><th>max_collater_valueofguarantee_876L</th><th>max_collaterals_typeofguarante_359M</th><th>max_collaterals_typeofguarante_669M</th><th>max_num_group1_12</th><th>max_num_group2</th><th>max_pmts_dpd_1073P</th><th>max_pmts_dpd_303P</th><th>max_pmts_month_158T</th><th>max_pmts_month_706T</th><th>max_pmts_overdue_1140A</th><th>max_pmts_overdue_1152A</th><th>max_pmts_year_1139T</th><th>max_pmts_year_507T</th><th>max_subjectroles_name_541M</th><th>max_subjectroles_name_838M</th><th>mean_pmts_dpd_1073P</th><th>mean_pmts_dpd_303P</th><th>mean_pmts_overdue_1140A</th><th>mean_pmts_overdue_1152A</th><th>var_pmts_dpd_1073P</th><th>var_pmts_dpd_303P</th><th>var_pmts_overdue_1140A</th><th>var_pmts_overdue_1152A</th><th>year</th><th>day</th></tr><tr><td>u32</td><td>u32</td><td>u8</td><td>u8</td><td>i16</td><td>u8</td><td>i16</td><td>f32</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>i8</td><td>u8</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>u8</td><td>i16</td><td>f32</td><td>i16</td><td>u8</td><td>i16</td><td>i16</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>u16</td><td>u8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>u16</td><td>u8</td></tr></thead><tbody><tr><td>1542964</td><td>201909</td><td>37</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-12009</td><td>3.0</td><td>8.0</td><td>2.0</td><td>12.0</td><td>2.0</td><td>&quot;a55475b1&quot;</td><td>&quot;717ddd49&quot;</td><td>&quot;a55475b1&quot;</td><td>5.0</td><td>4.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>12.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4.0</td><td>1884.800049</td><td>&quot;DEDUCTION_6&quot;</td><td>14</td><td>14</td><td>null</td><td>9.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>1958.400024</td><td>&hellip;</td><td>20000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>3</td><td>23</td><td>76.0</td><td>68.0</td><td>12.0</td><td>12.0</td><td>7347.834473</td><td>8434.799805</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>16.227272</td><td>10.766666</td><td>1662.138428</td><td>1129.526733</td><td>414.564941</td><td>333.081604</td><td>3.620474e6</td><td>4709531.5</td><td>2019</td><td>18</td></tr><tr><td>1835030</td><td>202004</td><td>66</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-16419</td><td>4.0</td><td>6.0</td><td>1.0</td><td>9.0</td><td>3.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>11.0</td><td>6.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>9.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>7.0</td><td>3.0</td><td>0.0</td><td>29187.259766</td><td>11545.200195</td><td>&hellip;</td><td>95600.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>5.5e6</td><td>3.2e6</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>13</td><td>35</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2021.0</td><td>2021.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2020</td><td>13</td></tr><tr><td>1004939</td><td>202008</td><td>84</td><td>0</td><td>null</td><td>null</td><td>null</td><td>160114.828125</td><td>-23603</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>&quot;2fc785b2&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>2.0</td><td>0.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>2920.199951</td><td>&hellip;</td><td>64000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>450000.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>4</td><td>23</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2021.0</td><td>2021.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2020</td><td>15</td></tr><tr><td>1711014</td><td>201912</td><td>51</td><td>0</td><td>null</td><td>14</td><td>null</td><td>null</td><td>-22155</td><td>1.0</td><td>3.0</td><td>0.0</td><td>13.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>9.0</td><td>10.0</td><td>&quot;b6cabe76&quot;</td><td>&quot;a55475b1&quot;</td><td>13.0</td><td>null</td><td>13126.600586</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>&quot;PENSION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>7.0</td><td>17.0</td><td>0.0</td><td>58006.199219</td><td>4117.200195</td><td>&hellip;</td><td>37000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>65000.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>8</td><td>35</td><td>0.0</td><td>2680.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>17998.0</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>981.906982</td><td>0.0</td><td>9278.480469</td><td>0.0</td><td>1012038.5</td><td>0.0</td><td>4.7851436e7</td><td>2019</td><td>27</td></tr><tr><td>42769</td><td>202001</td><td>53</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-8621</td><td>0.0</td><td>1.0</td><td>0.0</td><td>4.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>5.0</td><td>0.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>4.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>1.0</td><td>1.0</td><td>null</td><td>null</td><td>2472.400146</td><td>&hellip;</td><td>70000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>3</td><td>23</td><td>5.0</td><td>null</td><td>12.0</td><td>null</td><td>2343.290039</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.137255</td><td>null</td><td>125.676628</td><td>null</td><td>0.520784</td><td>null</td><td>260681.34375</td><td>null</td><td>2020</td><td>8</td></tr><tr><td>1872407</td><td>202006</td><td>77</td><td>0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>-14424</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;2fc785b2&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>2.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>1.0</td><td>1.0</td><td>0.0</td><td>70506.5625</td><td>3602.400146</td><td>&hellip;</td><td>24000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>6</td><td>35</td><td>0.0</td><td>79.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>5397.728027</td><td>2021.0</td><td>2021.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>3.923077</td><td>0.0</td><td>358.44162</td><td>0.0</td><td>155.469757</td><td>0.0</td><td>1.097857e6</td><td>2020</td><td>29</td></tr><tr><td>2616312</td><td>201908</td><td>34</td><td>0</td><td>null</td><td>null</td><td>-21121</td><td>null</td><td>-21121</td><td>2.0</td><td>2.0</td><td>0.0</td><td>8.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>9.0</td><td>7.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>8.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6.0</td><td>11214.470703</td><td>&quot;DEDUCTION_6&quot;</td><td>14</td><td>14</td><td>null</td><td>7.0</td><td>7.0</td><td>0.0</td><td>36581.199219</td><td>5391.200195</td><td>&hellip;</td><td>30000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>100000.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>10</td><td>35</td><td>0.0</td><td>8.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>1405.599976</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.115385</td><td>0.0</td><td>24.805769</td><td>0.0</td><td>0.646751</td><td>0.0</td><td>28209.898438</td><td>2019</td><td>30</td></tr><tr><td>988781</td><td>202006</td><td>74</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-20275</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>&quot;2fc785b2&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>12703.799805</td><td>&hellip;</td><td>60000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>826451.3125</td><td>&quot;c7a5ad39&quot;</td><td>&quot;a55475b1&quot;</td><td>3</td><td>35</td><td>null</td><td>1.0</td><td>null</td><td>12.0</td><td>null</td><td>2255.982178</td><td>null</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>0.018182</td><td>null</td><td>39.578636</td><td>null</td><td>0.018182</td><td>null</td><td>89288.695312</td><td>2020</td><td>5</td></tr><tr><td>1567473</td><td>201910</td><td>39</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-9926</td><td>3.0</td><td>4.0</td><td>1.0</td><td>7.0</td><td>2.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>7.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.0</td><td>4604.800293</td><td>&quot;DEDUCTION_6&quot;</td><td>14</td><td>14</td><td>null</td><td>8.0</td><td>5.0</td><td>0.0</td><td>9415.200195</td><td>2688.0</td><td>&hellip;</td><td>30000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>1</td><td>35</td><td>1.0</td><td>3.0</td><td>12.0</td><td>12.0</td><td>514.799988</td><td>9.0</td><td>2020.0</td><td>2019.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.026316</td><td>0.428571</td><td>13.547368</td><td>1.285714</td><td>0.026316</td><td>1.285714</td><td>6974.185059</td><td>11.571428</td><td>2019</td><td>5</td></tr><tr><td>114117</td><td>201903</td><td>8</td><td>0</td><td>-8225</td><td>null</td><td>-25414</td><td>null</td><td>-25414</td><td>1.0</td><td>1.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;39a0853f&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>1.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>2.0</td><td>18193.900391</td><td>null</td><td>null</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>14</td><td>null</td><td>null</td><td>2.0</td><td>0.0</td><td>0.0</td><td>null</td><td>7789.600098</td><td>&hellip;</td><td>24000.0</td><td>10267.666016</td><td>0</td><td>-981</td><td>10267.666016</td><td>-981</td><td>0</td><td>-981</td><td>-981</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>35</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 472)\n",
       "\n",
       " case_id  month   week_num  target    var_pmts_overdue_11  var_pmts_overdue_1  year  day \n",
       " ---      ---     ---       ---        40A                  152A                ---   --- \n",
       " u32      u32     u8        u8         ---                  ---                 u16   u8  \n",
       "                                       f32                  f32                           \n",
       "\n",
       " 1542964  201909  37        0         3.620474e6           4709531.5           2019  18  \n",
       " 1835030  202004  66        0         0.0                  0.0                 2020  13  \n",
       " 1004939  202008  84        0         0.0                  0.0                 2020  15  \n",
       " 1711014  201912  51        0         0.0                  4.7851436e7         2019  27  \n",
       " 42769    202001  53        0         260681.34375         null                2020  8   \n",
       " 1872407  202006  77        0         0.0                  1.097857e6          2020  29  \n",
       " 2616312  201908  34        0         0.0                  28209.898438        2019  30  \n",
       " 988781   202006  74        0         null                 89288.695312        2020  5   \n",
       " 1567473  201910  39        0         6974.185059          11.571428           2019  5   \n",
       " 114117   201903  8         0         0.0                  null                2019  1   \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del data_store\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Train data shape: {df_train.shape}\")\n",
    "display(df_train.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e13e0cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:56:24.009175Z",
     "iopub.status.busy": "2025-10-19T04:56:24.008783Z",
     "iopub.status.idle": "2025-10-19T04:56:27.888597Z",
     "shell.execute_reply": "2025-10-19T04:56:27.887888Z"
    },
    "papermill": {
     "duration": 3.885434,
     "end_time": "2025-10-19T04:56:27.889848",
     "exception": false,
     "start_time": "2025-10-19T04:56:24.004414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_base loaded into memory.\n",
      "File test_static_cb_0 loaded into memory.\n",
      "File test_static_0_0 loaded into memory.\n",
      "File test_static_0_2 loaded into memory.\n",
      "File test_static_0_1 loaded into memory.\n",
      "File test_applprev_1_2 loaded into memory.\n",
      "File test_applprev_1_0 loaded into memory.\n",
      "File test_applprev_1_1 loaded into memory.\n",
      "File test_tax_registry_a_1 loaded into memory.\n",
      "File test_tax_registry_b_1 loaded into memory.\n",
      "File test_tax_registry_c_1 loaded into memory.\n",
      "File test_credit_bureau_a_1_3 loaded into memory.\n",
      "File test_credit_bureau_a_1_2 loaded into memory.\n",
      "File test_credit_bureau_a_1_1 loaded into memory.\n",
      "File test_credit_bureau_a_1_4 loaded into memory.\n",
      "File test_credit_bureau_a_1_0 loaded into memory.\n",
      "File test_credit_bureau_b_1 loaded into memory.\n",
      "File test_other_1 loaded into memory.\n",
      "File test_person_1 loaded into memory.\n",
      "File test_deposit_1 loaded into memory.\n",
      "File test_debitcard_1 loaded into memory.\n",
      "File test_credit_bureau_a_2_3 loaded into memory.\n",
      "File test_credit_bureau_a_2_9 loaded into memory.\n",
      "File test_credit_bureau_a_2_2 loaded into memory.\n",
      "File test_credit_bureau_a_2_11 loaded into memory.\n",
      "File test_credit_bureau_a_2_1 loaded into memory.\n",
      "File test_credit_bureau_a_2_6 loaded into memory.\n",
      "File test_credit_bureau_a_2_5 loaded into memory.\n",
      "File test_credit_bureau_a_2_0 loaded into memory.\n",
      "File test_credit_bureau_a_2_7 loaded into memory.\n",
      "File test_credit_bureau_a_2_10 loaded into memory.\n",
      "File test_credit_bureau_a_2_8 loaded into memory.\n",
      "File test_credit_bureau_a_2_4 loaded into memory.\n",
      "File test_credit_bureau_b_2 loaded into memory.\n"
     ]
    }
   ],
   "source": [
    "data_store: dict = {\n",
    "    \"df_base\": SchemaGen.scan_files(TEST_DIR / \"test_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_static_cb_0.parquet\"),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_other_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_person_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_deposit_1.parquet\", 1),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n",
    "        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b8b22c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:56:27.901142Z",
     "iopub.status.busy": "2025-10-19T04:56:27.900619Z",
     "iopub.status.idle": "2025-10-19T04:56:28.253757Z",
     "shell.execute_reply": "2025-10-19T04:56:28.252904Z"
    },
    "papermill": {
     "duration": 0.359793,
     "end_time": "2025-10-19T04:56:28.254970",
     "exception": false,
     "start_time": "2025-10-19T04:56:27.895177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe \"df_train\" is 0.0445 MB.\n",
      "Memory usage of dataframe \"df_train\" became 0.0324 MB.\n",
      "Memory usage of dataframe \"df_test\" is 0.0184 MB.\n",
      "Memory usage of dataframe \"df_test\" became 0.0173 MB.\n",
      "Test data shape: (10, 471)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_test: pl.DataFrame = (\n",
    "    SchemaGen.join_dataframes(**data_store)\n",
    "    .pipe(transform_cols)\n",
    "    .pipe(handle_dates)\n",
    "    .select([col for col in df_train.columns if col != \"target\"])\n",
    "    .pipe(Utility.reduce_memory_usage, \"df_test\")\n",
    ")\n",
    "\n",
    "del data_store\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Test data shape: {df_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a42812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:56:28.266206Z",
     "iopub.status.busy": "2025-10-19T04:56:28.265818Z",
     "iopub.status.idle": "2025-10-19T04:56:43.814752Z",
     "shell.execute_reply": "2025-10-19T04:56:43.814159Z"
    },
    "papermill": {
     "duration": 15.55585,
     "end_time": "2025-10-19T04:56:43.816073",
     "exception": false,
     "start_time": "2025-10-19T04:56:28.260223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, cat_cols = Utility.to_pandas(df_train)\n",
    "df_test, cat_cols = Utility.to_pandas(df_test, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeb77aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:56:43.827676Z",
     "iopub.status.busy": "2025-10-19T04:56:43.827186Z",
     "iopub.status.idle": "2025-10-19T04:56:43.832577Z",
     "shell.execute_reply": "2025-10-19T04:56:43.832007Z"
    },
    "papermill": {
     "duration": 0.012178,
     "end_time": "2025-10-19T04:56:43.833658",
     "exception": false,
     "start_time": "2025-10-19T04:56:43.821480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VotingModel(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A voting ensemble model that combines predictions from multiple estimators.\n",
    "\n",
    "    Parameters:\n",
    "    - estimators (list): List of base estimators.\n",
    "\n",
    "    Attributes:\n",
    "    - estimators (list): List of base estimators.\n",
    "\n",
    "    Methods:\n",
    "    - fit(X, y=None): Fit the model to the training data.\n",
    "    - predict(X): Predict class labels for samples.\n",
    "    - predict_proba(X): Predict class probabilities for samples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimators: list[BaseEstimator]):\n",
    "        \"\"\"\n",
    "        Initialize the VotingModel with a list of base estimators.\n",
    "\n",
    "        Args:\n",
    "        - estimators (list): List of base estimators.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit the model to the training data.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "        - y: Target labels (ignored).\n",
    "\n",
    "        Returns:\n",
    "        - self: Returns the instance itself.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Predicted class labels.\n",
    "        \"\"\"\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for samples.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Predicted class probabilities.\n",
    "        \"\"\"\n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5803562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:56:43.844443Z",
     "iopub.status.busy": "2025-10-19T04:56:43.844244Z",
     "iopub.status.idle": "2025-10-19T04:56:43.862846Z",
     "shell.execute_reply": "2025-10-19T04:56:43.862088Z"
    },
    "papermill": {
     "duration": 0.025385,
     "end_time": "2025-10-19T04:56:43.864033",
     "exception": false,
     "start_time": "2025-10-19T04:56:43.838648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subm: pd.DataFrame = pd.read_csv(ROOT / \"sample_submission.csv\")\n",
    "df_subm = df_subm.set_index(\"case_id\")\n",
    "\n",
    "device: str = \"gpu\"\n",
    "est_cnt: int = 6000\n",
    "\n",
    "DRY_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a303842e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T04:56:43.876489Z",
     "iopub.status.busy": "2025-10-19T04:56:43.876070Z",
     "iopub.status.idle": "2025-10-19T10:14:49.886527Z",
     "shell.execute_reply": "2025-10-19T10:14:49.885819Z"
    },
    "papermill": {
     "duration": 19086.025714,
     "end_time": "2025-10-19T10:14:49.895407",
     "exception": false,
     "start_time": "2025-10-19T04:56:43.869693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.842685\n",
      "[200]\tvalid_0's auc: 0.850735\n",
      "[300]\tvalid_0's auc: 0.853438\n",
      "[400]\tvalid_0's auc: 0.854517\n",
      "[500]\tvalid_0's auc: 0.854863\n",
      "[600]\tvalid_0's auc: 0.855001\n",
      "[700]\tvalid_0's auc: 0.855109\n",
      "[800]\tvalid_0's auc: 0.855291\n",
      "[900]\tvalid_0's auc: 0.855389\n",
      "[1000]\tvalid_0's auc: 0.85548\n",
      "[1100]\tvalid_0's auc: 0.855477\n",
      "Early stopping, best iteration is:\n",
      "[1052]\tvalid_0's auc: 0.855564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.842244\n",
      "[200]\tvalid_0's auc: 0.850447\n",
      "[300]\tvalid_0's auc: 0.852813\n",
      "[400]\tvalid_0's auc: 0.854069\n",
      "[500]\tvalid_0's auc: 0.854796\n",
      "[600]\tvalid_0's auc: 0.855057\n",
      "[700]\tvalid_0's auc: 0.855219\n",
      "[800]\tvalid_0's auc: 0.855248\n",
      "Early stopping, best iteration is:\n",
      "[747]\tvalid_0's auc: 0.855324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.846855\n",
      "[200]\tvalid_0's auc: 0.855398\n",
      "[300]\tvalid_0's auc: 0.858137\n",
      "[400]\tvalid_0's auc: 0.859259\n",
      "[500]\tvalid_0's auc: 0.859696\n",
      "[600]\tvalid_0's auc: 0.859855\n",
      "[700]\tvalid_0's auc: 0.860189\n",
      "[800]\tvalid_0's auc: 0.860362\n",
      "[900]\tvalid_0's auc: 0.86048\n",
      "[1000]\tvalid_0's auc: 0.860549\n",
      "[1100]\tvalid_0's auc: 0.860748\n",
      "[1200]\tvalid_0's auc: 0.860764\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's auc: 0.860851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.84682\n",
      "[200]\tvalid_0's auc: 0.854793\n",
      "[300]\tvalid_0's auc: 0.857799\n",
      "[400]\tvalid_0's auc: 0.858859\n",
      "[500]\tvalid_0's auc: 0.859349\n",
      "[600]\tvalid_0's auc: 0.859685\n",
      "[700]\tvalid_0's auc: 0.859916\n",
      "[800]\tvalid_0's auc: 0.860105\n",
      "[900]\tvalid_0's auc: 0.860143\n",
      "[1000]\tvalid_0's auc: 0.860359\n",
      "[1100]\tvalid_0's auc: 0.860437\n",
      "[1200]\tvalid_0's auc: 0.860438\n",
      "Early stopping, best iteration is:\n",
      "[1133]\tvalid_0's auc: 0.860503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.840931\n",
      "[200]\tvalid_0's auc: 0.849836\n",
      "[300]\tvalid_0's auc: 0.853097\n",
      "[400]\tvalid_0's auc: 0.854121\n",
      "[500]\tvalid_0's auc: 0.854538\n",
      "[600]\tvalid_0's auc: 0.854941\n",
      "[700]\tvalid_0's auc: 0.85528\n",
      "[800]\tvalid_0's auc: 0.855543\n",
      "[900]\tvalid_0's auc: 0.855567\n",
      "[1000]\tvalid_0's auc: 0.855761\n",
      "[1100]\tvalid_0's auc: 0.855742\n",
      "[1200]\tvalid_0's auc: 0.855813\n",
      "[1300]\tvalid_0's auc: 0.855818\n",
      "[1400]\tvalid_0's auc: 0.855926\n",
      "Early stopping, best iteration is:\n",
      "[1393]\tvalid_0's auc: 0.855944\n",
      "\n",
      "CV AUC scores for CatBoost: [0.8534786390111323, 0.8535005708868519, 0.8591647273306314, 0.858231367001639, 0.8536889292997569]\n",
      "Maximum CV AUC score for Catboost: 0.8591647273306314\n",
      "\n",
      "CV AUC scores for LGBM: [0.855564329529698, 0.8553239049957821, 0.8608513017764637, 0.8605034238833711, 0.85594398032189]\n",
      "Maximum CV AUC score for LGBM: 0.8608513017764637\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.drop(columns=[\"target\", \"case_id\", \"week_num\"])\n",
    "y = df_train[\"target\"]\n",
    "col = 'mean_refreshdate_3813885D'\n",
    "weeks = df_train[\"week_num\"]\n",
    "\n",
    "del df_train\n",
    "gc.collect()\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"device\": \"cpu\",\n",
    "    \"extra_trees\": True,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"l1_regularization\": 0.1,\n",
    "    \"l2_regularization\": 10,\n",
    "    \"max_depth\": 20,\n",
    "    \"metric\": \"auc\",\n",
    "    \"n_estimators\": 2000,\n",
    "    \"num_leaves\": 64,\n",
    "    \"objective\": \"binary\",\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "\n",
    "fitted_models_cat = []\n",
    "fitted_models_lgb = []\n",
    "\n",
    "cv_scores_cat = []\n",
    "cv_scores_lgb = []\n",
    "\n",
    "for idx_train, idx_valid in cv.split(X, y, groups=weeks):\n",
    "    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_cols)\n",
    "    val_pool = Pool(X_valid, y_valid, cat_features=cat_cols)\n",
    "\n",
    "    clf = CatBoostClassifier(\n",
    "        best_model_min_trees = 1200,\n",
    "        boosting_type = \"Plain\",\n",
    "        eval_metric = \"AUC\",\n",
    "        iterations = est_cnt,\n",
    "        learning_rate = 0.05,\n",
    "        l2_leaf_reg = 10,\n",
    "        max_leaves = 64,\n",
    "        random_seed = 42,\n",
    "        task_type = \"GPU\",\n",
    "        use_best_model = True\n",
    "    )\n",
    "\n",
    "    clf.fit(train_pool, eval_set=val_pool, verbose=False)\n",
    "    fitted_models_cat.append(clf)\n",
    "    y_pred_valid = clf.predict_proba(X_valid)[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores_cat.append(auc_score)\n",
    "\n",
    "    X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "    X_valid[cat_cols] = X_valid[cat_cols].astype(\"category\")\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        callbacks=[lgb.log_evaluation(100), lgb.early_stopping(100)],\n",
    "    )\n",
    "    fitted_models_lgb.append(model)\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores_lgb.append(auc_score)\n",
    "\n",
    "\n",
    "model = VotingModel(fitted_models_cat + fitted_models_lgb)\n",
    "\n",
    "print(f\"\\nCV AUC scores for CatBoost: {cv_scores_cat}\")\n",
    "print(f\"Maximum CV AUC score for Catboost: {max(cv_scores_cat)}\", end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"CV AUC scores for LGBM: {cv_scores_lgb}\")\n",
    "print(f\"Maximum CV AUC score for LGBM: {max(cv_scores_lgb)}\", end=\"\\n\\n\")\n",
    "\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e2fc00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T10:14:49.912130Z",
     "iopub.status.busy": "2025-10-19T10:14:49.911872Z",
     "iopub.status.idle": "2025-10-19T10:14:50.316605Z",
     "shell.execute_reply": "2025-10-19T10:14:50.315861Z"
    },
    "papermill": {
     "duration": 0.414722,
     "end_time": "2025-10-19T10:14:50.317850",
     "exception": false,
     "start_time": "2025-10-19T10:14:49.903128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test: pd.DataFrame = df_test.drop(columns=[\"week_num\"]).set_index(\"case_id\")\n",
    "\n",
    "X_test[cat_cols] = X_test[cat_cols].astype(\"category\")\n",
    "\n",
    "y_pred: pd.Series = pd.Series(model.predict_proba(X_test)[:, 1], index=X_test.index)\n",
    "\n",
    "df_subm[\"score\"] = y_pred\n",
    "\n",
    "\n",
    "condition = X_test[col] < (X_test[col].max() - X_test[col].min())/2 + X_test[col].min()\n",
    "df_subm.loc[condition, 'score'] = (df_subm.loc[condition, 'score'] - 0.01).clip(0)\n",
    "\n",
    "df_subm.to_csv(\"submission.csv\")\n",
    "\n",
    "del X_test, y_pred, df_subm\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19245.083854,
   "end_time": "2025-10-19T10:14:52.802449",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-19T04:54:07.718595",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
